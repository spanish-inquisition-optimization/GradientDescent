{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Поиск с учётом условий Вольфе\n",
    "\n",
    "## Реализация одномерного поиска с учётом условий Вольфе\n",
    "\n",
    "Напомним, что метод одномерного поиска называют удовлетворяющим сильным условиям Вольфе, если для всех выбранных им $\\alpha$\n",
    "\n",
    "1. $f(x_k + \\alpha_k p_k) \\le f(x_k) + c_1 \\alpha_k \\nabla f_k^T p_k$\n",
    "2. $|\\nabla f^T(x_k + \\alpha_k p_k) p_k| \\ge c_2 |\\nabla f_k^T p_k|$\n",
    "где $c_1, c_2$ - константы, такие что $0 < c_1 < c_2 < 1$\n",
    "\n",
    "В обозначениях $\\varphi(\\alpha) = f(x_k + \\alpha p_k)$ это равносильно\n",
    "\n",
    "1. $\\varphi(\\alpha_k) \\le \\varphi(0) + c_1 \\alpha_k \\varphi'(0)$\n",
    "2. $|\\varphi'(\\alpha_k)| \\ge c_2 |\\varphi'(0)|$\n",
    "\n",
    "Для нахождения подходящего $\\alpha$ воспользуемся следующим алгоритмом:\n",
    "Положим $\\alpha_0$ = 0, $\\alpha_{max}: \\varphi(\\alpha_{max}) > \\varphi(0) + c_1 \\alpha_{max} \\varphi'(0), \\alpha_1 = \\alpha_{max} / 2$.\n",
    "И будем увеличивать $\\alpha_i$, пока не получим выполнения одного из следующих условий:\n",
    "\n",
    "1. $\\varphi(\\alpha_i) \\le \\varphi(0) + c_1 \\alpha_i \\varphi'(0)$ или же $\\varphi(\\alpha_{i}) \\ge \\varphi(\\alpha_{i-1})$ не на первом шаге. В этом случае в качестве результата предъявим $zoom(\\alpha_{i-1}, \\alpha_i)$ (определение $zoom$, выбирающего точки из интервала, ограниченного $\\alpha_{i-1}$ и $\\alpha_i$ дадим позже).\n",
    "2. $|\\varphi'(\\alpha_i)| \\le -c_2 \\varphi'(0)$. В качестве результата предъявим $\\alpha_i$\n",
    "3. $\\varphi'(\\alpha_i) \\ge 0$. В качестве результата предъявим $zoom(\\alpha_i, \\alpha_{i-1})$\n",
    "Иначе положим $\\alpha_{i+1} = \\frac{\\alpha_{max} + \\alpha_i}{2}$ и перейдём на следующую итерацию.\n",
    "\n",
    "Уточним, как $zoom$ находит нужную нам точку.\n",
    "\n",
    "Утверждается, что на момент вызова $zoom(\\alpha_{left}, \\alpha_{right})$ выполнены следующие условия:\n",
    "\n",
    "1. Внутри интервала, ограниченного $\\alpha_{left}$ и $\\alpha_{right}$ существует точка, удовлетворяющая строгим условиям Вольфе.\n",
    "2. $\\varphi'(\\alpha_{left}) (\\alpha_{right} - \\alpha_{left}) < 0$\n",
    "3. Среди всех полученных на данный момент $\\alpha$, удовлетворяющим 1 условию Вольфе значение $\\varphi(\\alpha_{left})$ минимально.\n",
    "\n",
    "Сам $zoom$ выполняет следующий алгоритм:\n",
    "Положим $\\alpha_{mid} = \\frac{\\alpha_{left} + \\alpha_{right}}{2}$.\n",
    "Если $\\varphi(\\alpha_{mid}) \\le \\varphi(0) + c_1 \\alpha_{mid} \\varphi'(0)$ или $\\varphi(\\alpha_{mid}) \\ge \\varphi(\\alpha_{left})$, то положим $\\alpha_{right} = \\alpha_{mid}$ и перейдём на следующую итерацию.\n",
    "Иначе же если $|\\varphi'(\\alpha_{mid})| \\le -c_2 \\varphi'(0)$, то $\\alpha_{mid}$ удовлетворяет обоим условиям Вольфе, предъявим её как результат.\n",
    "Иначе $\\varphi(\\alpha_{mid}) (\\alpha_{right} - \\alpha_{left}) \\ge 0$ положим $\\alpha_{high} = \\alpha_{low}$\n",
    "В конце присвоим $\\alpha_{left} = \\alpha_{mid}$ и перейдём к следующей итерации.\n",
    "\n",
    "Заметим, что инвариант из трёх условий сохраняется и после выполнения итерации, то есть он верен в начале любой итерации. Тогда при сужении интервала поиска в конце мы найдём требуемое $\\alpha$.\n",
    "\n",
    "Протестируем полученный метод линейного поиска.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сравнение методов линейного поиска, backtracking method\n",
    "\n",
    "Про реализацию и теорОбоснование `Backtracking method` — см. в первых частях.\n",
    "\n",
    "## Что хотим от line search метода\n",
    "\n",
    "Мы уже собрали целый зоопарк методов линейного поиска:\n",
    "- БинПоиск по градиенту (с остановкой по достижению малого значения градиента и/или размера ворот $r - l$, с опциональным обрубанием по количеству итераций)\n",
    "- Золотое сечение (по количеству итераций)\n",
    "- Фибоначчи (по количеству итераций)\n",
    "- Метод, базирующийся на условиях Вольфе (aka backtracking method)\n",
    "\n",
    "Здесь нужно проанализировать, какие `line searcher`-ы _лучше_ себя показывают. Что от такого алгоритма требуется?\n",
    "\n",
    "1. Конечно же, хорошо сходиться\n",
    "2. Произвести _достаточно_ точный поиск, чтобы заЭксплойтить это направление поиска\n",
    "3. Но не переусердствовать: не слишком долго искать, чтобы сэкономить время\n",
    "\n",
    "Пункт 1 очевиден и не настолько интересен.\n",
    "А вот между 2. и 3. налицо трейд-офф по поводу того, насколько быстро надо останавливаться. Для каждой конкретной функции ответ на этот вопрос разный — и хороший line search метод — тот, который хорошо умеет его давать.\n",
    "Причём давать для самых разных паттернов ландшафта, масштабирований и т.д.\n",
    "\n",
    "## Как производить оценку\n",
    "\n",
    "Раз уж так важна устойчивость и догадливость метода, заведём набор _интересных_ функций и попробуем запустить методы на них (метод проходит все функции с одинаковыми гиперпараметрами — приближено к реальности).\n",
    "\n",
    "Функции:\n",
    "- квадратичная (какое-то/какие-то число(а) обусловленности, размерность(и))\n",
    "- умножение на разные константы (маленькую, большую)/масштабирование аргументов\n",
    "- непредсказуемый рельеф (всё ещё выпуклая, но где-то сильно убывает, где-то — _не очень_…)\n",
    "\n",
    "Теперь — как оценивать результат. В целом — чем меньше действий, тем лучше. В реальной жизни обычно речь идёт о процессорном времени, но здесь измерять время — это лишняя возня, потеря точности и, главное, bias за счёт того, что у тестовых функций (к примеру, квадратичной) может быть _странное_ отношение времён вычисления функции и градиента. Это затрудняет оценку самого метода линейного поиска, а также не соответствует реальности. Поэтому будем считать, что целевая функция (чем меньше, тем лучше) в данном случае $\\operatorname{computations}(f) + \\operatorname{computations}(\\nabla f)$.\n",
    "\n",
    "Ожидаем, что методы с фиксированным количеством итераций будут хорошо себя проявлять только для конкретных функций фиксированного уровня сложности, а для других — либо делать избыточную работу внутри каждой итерации, либо плохо отрабатывать очередное направление → потребуется много внешних итераций, иногда даже вообще не сходиться.\n",
    "\n",
    "А про методы с остановкой по фиксированному $\\varepsilon$ ожидаем, что он будет плохо устойчив к масштабированию функции/градиента."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реальность соответствует ожиданиям: backtracking method умеет с одной стороны вовремя остановиться, с другой — чётко отрабатывает (→ не расходится), когда это нужно."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from core.gradient_descent import *\n",
    "from core.visualizer import *\n",
    "from core.optimizer_evaluator import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic : f called 51 times, f' called 50 times, total score: 101\n",
      "Trigonometric : f called 101 times, f' called 100 times, total score: 201\n",
      "GD diverged at Rosenbrock (got vector norm 67215268.07617551 after 3 steps), such a pity…\n",
      "GD diverged at 100-dimensional quadratic with k = 100 (got vector norm 2.4860330689387453e+18 after 16 steps), such a pity…\n"
     ]
    }
   ],
   "source": [
    "test_linear_search(fixed_step_search(0.1), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic : f called 6 times, f' called 5 times, total score: 11\n",
      "Trigonometric : f called 4 times, f' called 3 times, total score: 7\n",
      "GD diverged at Rosenbrock (got vector norm 697073038160.035 after 3 steps), such a pity…\n",
      "GD diverged at 100-dimensional quadratic with k = 100 (got vector norm 8.738122483458636e+19 after 10 steps), such a pity…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Education\\MethOpt\\GradientDescent\\core\\visualizer.py:114: RuntimeWarning: overflow encountered in long_scalars\n",
      "  return alpha * (x[0] - 5) ** 2 + (x[1] - 7) ** 2\n"
     ]
    }
   ],
   "source": [
    "test_linear_search(fixed_step_search(1), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic : f called 89 times, f' called 39 times, total score: 128\n",
      "Trigonometric : f called 720 times, f' called 299 times, total score: 1019\n",
      "Rosenbrock : f called 262 times, f' called 60 times, total score: 322\n",
      "100-dimensional quadratic with k = 100 : f called 3783 times, f' called 1071 times, total score: 4854\n"
     ]
    }
   ],
   "source": [
    "test_linear_search(wolfe_conditions_search(0.05, 0.9), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic : f called 397 times, f' called 22 times, total score: 419\n",
      "Trigonometric : f called 1799 times, f' called 99 times, total score: 1898\n",
      "GD diverged at Rosenbrock (got vector norm 647125619911.2137 after 6 steps), such a pity…\n",
      "100-dimensional quadratic with k = 100 : f called 7381 times, f' called 410 times, total score: 7791\n"
     ]
    }
   ],
   "source": [
    "test_linear_search(fibonacci_search(15), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic : f called 463 times, f' called 14 times, total score: 477\n",
      "Trigonometric : f called 588 times, f' called 17 times, total score: 605\n",
      "Rosenbrock : f called 661 times, f' called 20 times, total score: 681\n",
      "100-dimensional quadratic with k = 100 : f called 12178 times, f' called 369 times, total score: 12547\n"
     ]
    }
   ],
   "source": [
    "test_linear_search(fibonacci_search(30), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic : f called 687 times, f' called 14 times, total score: 701\n",
      "Trigonometric : f called 864 times, f' called 17 times, total score: 881\n",
      "Rosenbrock : f called 981 times, f' called 20 times, total score: 1001\n",
      "100-dimensional quadratic with k = 100 : f called 20189 times, f' called 412 times, total score: 20601\n"
     ]
    }
   ],
   "source": [
    "test_linear_search(golden_ratio_search, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
